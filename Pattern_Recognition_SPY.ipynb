{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tslearn import clustering\n",
    "import matplotlib.pylab as plt\n",
    "from tslearn.clustering import KShape\n",
    "import matplotlib as mpl\n",
    "from sklearn import metrics\n",
    "from tslearn.metrics import soft_dtw\n",
    "from tslearn.metrics import dtw\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This case we will analyze the CLOSE price of SPY from 1993 to 2020.\n",
    "# --   train a dataset with time series of length 15 (I.e from T to T+15) and assign them to 10 different clusters\n",
    "# --   apply a self-computed score function to quantity the quality of clusters\n",
    "# --   show some analysis and graphs based on the clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_data(path, header=None, sep=None, cols=None):\n",
    "    df = pd.read_csv(path, header=header, sep=sep)\n",
    "    if cols:\n",
    "        df.columns = cols\n",
    "    return df\n",
    "\n",
    "def generate_training_data(df, length, step, start_index, end_index, col):\n",
    "    # Store the start index of each time series in the training data\n",
    "    X_index = []\n",
    "    bStart = True\n",
    "    index = start_index\n",
    "    while index < end_index:\n",
    "        X_index.append(index)\n",
    "        series = df[col].iloc[index:index+length].values.reshape(1,-1)\n",
    "        # normalize each time series\n",
    "        series = preprocessing.normalize(series)\n",
    "        if bStart:\n",
    "            X_train = series\n",
    "            bStart = False\n",
    "        else:\n",
    "            # concat new time series to training data\n",
    "            X_train = np.vstack((X_train,series))\n",
    "        index += step\n",
    "    X_index = np.asarray(X_index)\n",
    "    return (X_train, X_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data and generate training data set\n",
    "# Each time series of length 15, set step to 5, leave the last 100 observations for testing\n",
    "data = read_input_data('SPY.txt', sep=',', cols=['Date','Open','High','Low','Close','Volumn'])\n",
    "length = 15\n",
    "step = 5\n",
    "start_index = 0\n",
    "end_index = len(data) - 100\n",
    "X_train, X_index = generate_training_data(data, length, step, start_index, end_index, 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step is to train TimeSeriesKMeans model with preset distance metrics\n",
    "# we set the number of clusters to 10\n",
    "n_cluster = 10\n",
    "metric = 'dtw'\n",
    "km = TimeSeriesKMeans(n_clusters=n_cluster,metric=metric)\n",
    "labels_train = km.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try with our test data\n",
    "# When we generate the training data, we left the last 100 observations of SPY for testing purpose\n",
    "# Randomly pick one, predict with the model\n",
    "# Plot predicted cluster vs test time series\n",
    "rdm_idx = np.random.randint(85) + end_index\n",
    "X_test = data['Close'].iloc[rdm_idx:rdm_idx+length].values.reshape(1,-1)\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "test_label = km.predict(X_test)\n",
    "target_cluster = test_label[0]\n",
    "X_cluster_test = X_train[labels_train == target_cluster]\n",
    "plt.plot(range(1,length+1),np.median(X_cluster_test,axis=0),label='median trace of cluster ' + str(target_cluster))\n",
    "plt.plot(range(1,length+1),X_test.flatten(),label='test time series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cluster for pattern check\n",
    "def plt_cluster(i_cluster, X, labels, period, model, num_obs):\n",
    "    X_cluster = X[labels == i_cluster]\n",
    "    num_row = X_cluster.shape[0]\n",
    "    if num_row < 2:\n",
    "        return\n",
    "    plt.title('Cluster: {!r}'.format(i_cluster))\n",
    "    #plt.plot(range(period), model.cluster_centers_[i_cluster], label='Centroid')\n",
    "    size = min(num_row, num_obs)\n",
    "    # output at most size rows\n",
    "    random_indice = np.random.choice(num_row, size=size, replace=False)\n",
    "    for series in X_cluster[random_indice,:]:\n",
    "        if np.array_equal(model.cluster_centers_[i_cluster].flatten(),series):\n",
    "            continue\n",
    "        plt.plot(range(period), series)\n",
    "    #plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot 50 random time series in this cluster\n",
    "# to check if any pattern can be recognized (ascending, descending, convex, concave etc)\n",
    "plt_cluster(target_cluster, X_train, labels_train, length, km, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given cluster, find 5-day period returns after the pattern for all timeseries in the cluster\n",
    "def get_abs_cluster_return(df, index_arr, return_days, col):\n",
    "    return_arr = []\n",
    "    for index in index_arr:\n",
    "        r_temp = []\n",
    "        for day in return_days:\n",
    "            curr_index = index + day\n",
    "            prev_index = index + day - 1\n",
    "            if curr_index < len(df) and prev_index >= 0:\n",
    "                curr = df[col].iloc[curr_index]\n",
    "                prev = df[col].iloc[prev_index]\n",
    "                r = (np.log(curr) - np.log(prev)) * 100\n",
    "                r_temp.append(r)\n",
    "            else:\n",
    "                r_temp.append(\"\")\n",
    "        return_arr.append(r_temp)\n",
    "    return_arr = np.asarray(return_arr)\n",
    "    return return_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next let's calculate the return matrix of this cluster\n",
    "# for each time series in the cluster, we select end date T and then calculate the return from T+1 to T+5\n",
    "return_days = list(range(15,20))\n",
    "X_cluster_index = X_index[labels_train == target_cluster]\n",
    "abs_return_arr = get_abs_cluster_return(data, X_cluster_index, return_days, 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density(return_arr, day):\n",
    "    sort_return = np.sort(return_arr[:,day])\n",
    "    sns.distplot(sort_return, hist=True, kde=True, \n",
    "             bins=10, color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "    title = 'T+' + str(day+1)\n",
    "    plt.title('Density plot for return: {!r}'.format(title))\n",
    "    plt.xlabel('Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf(return_arr, day):\n",
    "    sort_return = np.sort(return_arr[:,day])\n",
    "    y = np.arange(1, len(sort_return)+1) / len(sort_return)\n",
    "    med_val = np.median(sort_return)\n",
    "    median = np.array([med_val for i in range(len(y))])\n",
    "    plt.plot(sort_return, y, marker='.', linestyle='none')\n",
    "    plt.plot(median, y, label='median')\n",
    "    title = 'T+' + str(day+1)\n",
    "    plt.title('ECDF plot for return: {!r}'.format(title))\n",
    "    plt.xticks(np.arange(np.floor(np.min(sort_return)),np.ceil(np.max(sort_return)) + 1,step=1))\n",
    "    plt.yticks(np.arange(0,1.1,step=0.1))\n",
    "    plt.xlabel(\"Return\")\n",
    "    plt.ylabel('ECDF')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution plot for return on day T+1\n",
    "plot_density(abs_return_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot empirical cumulative distribution plot for return on day T+1\n",
    "plot_ecdf(abs_return_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
